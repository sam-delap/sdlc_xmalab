{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to DeepXROMM!","text":""},{"location":"#getting-started","title":"Getting started","text":"<ol> <li>Follow the steps on our Installation page to get the package and its dependencies set up</li> <li>Follow the Usage guide to start training DeepLabCut networks for your data</li> <li>Visit our Config file reference to learn more about all of the different customization options available for training networks!</li> </ol>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>dlc-proj/        # Files generated by DeepLabCut\ntrainingdata/    # Trials for the network to train on\ntrials/          # Trials for the network to analyze\n</code></pre>"},{"location":"config/","title":"SDLC_XMALab Config File Reference","text":""},{"location":"config/#project-settings","title":"Project Settings","text":"<p>task: The animal/behavior you\u2019re trying to study. Pulled from the name given to your project folder experimenter: Your initials working_dir: The full directory path to your project folder path_config_file: The full directory path to the DeepLabCut config for your project dataset_name: An arbitary name for your dataset. Used when generating training data for DeepLabCut, which can be found in the <code>labeled-data</code> folder inside of your DLC project folder. </p>"},{"location":"config/#neural-network-customization","title":"Neural Network Customization","text":"<p>nframes: The number of frames of video that you tracked before giving the network to DeepLabCut. Automatically determined from CSVs if set to 0 max_iters: The maximum number of iterations to train the network for before automatically stopping training. Default is 150,000 tracking_threshold: Fraction of the total video frames to include in the training sample. Used to warn if the network detects too many/too few frames when extracting frames to be passed to the network tracking_mode: Determines the mode that sdlc_xmalab will attempt to train your network with:  </p> <ul> <li>2D - cam1 and cam2 will both be passed to the network from their respective video files  </li> <li>per_cam - cam1 and cam2 have their own networks</li> <li>rgb - cam1 and cam2 will be merged into an RGB video, with cam1 as the red channel, cam2 as the green channel, and a blank frame as the blue channel  </li> </ul> <p>swapped_markers: Set to \u2018true\u2019 to create artificial markers with swapped y coordinates (y coordinates of swapped-cam1 will be cam2\u2019s y coordinates). Only valid for the rgb tracking_mode crossed_markers: Set to \u2018true\u2019 to create artificial markers that are the result of multiplying the x/y positions of cam1 and cam2 together (cx_cam1_cam2_x = cam1_x * cam2_x). Only valid for the rgb tracking_mode.  </p>"},{"location":"config/#image-processing","title":"Image Processing","text":"<p>search_area: The area, in pixels, around which autocorrect() will search for a marker. The minimum is 10, the default is 15. threshold: Grayscale value for image thresholding. Pixels with a value above this number are turned black, while pixels with a value below this number are turned white. The default is 8 (grayscale values range from 0=black to 255=white). krad: The size of the kernel used for Gaussian filtering of the image. The larger the kernel, the higher the filtered radius of a marker. The default is 17 (left) vs. a krad of 3 (right).  </p> <p>gsigma: Responsible for small differences in image contrast. Can be modified as a last resort, but for the most part I would leave this alone. The default is 10. img_wt: Relative weight of the image when it is blended together with a blur. Typically you\u2019ll want this to be significantly higher than the blur, and the default will work well for most X-ray images. The default is 3.6. blur_wt: Relative weight of the blur when it is blended together with an image. Typically you\u2019ll want this to be significantly lower than the image, and the default will work well for most X-ray images. The default is -2.9. gamma: The level of contrast in the image. Higher gamma = lower contrast. The default is 0.1 (left) vs. gamma = 0.9 (right). Try to run with a level of gamma that avoids filtering out marker data, while not taking away valuable information from the image processing itself.</p>"},{"location":"config/#autocorrect-function-visualization","title":"Autocorrect() Function Visualization","text":"<p>trial_name: The trial to use for testing cam: The camera view to use for testing frame_num: The frame to use for testing   marker: The marker to use for testing test_autocorrect: Set to \u2018true\u2019 if you want to see/troubleshoot all of the post-processing steps that autocorrect goes through for a certain trial/cam/marker/frame combination  </p> <ul> <li>Requires a way to visualize image output like Jupyter Notebook</li> <li>You can also use the provided jupyter_test_autocorrect.ipynb file from the repo</li> </ul>"},{"location":"install/","title":"Installation Guide","text":""},{"location":"install/#prerequisites","title":"Prerequisites","text":"<ol> <li>A recent version of python. These docs were built using python 3.9.16</li> <li>If you're running locally, you'll also need DeepLabCut's dependencies</li> </ol>"},{"location":"install/#creating-a-conda-environment","title":"Creating a conda environment","text":"<p>Run the following command <pre><code>conda create -n your-env-name python=your-py-version\n</code></pre></p>"},{"location":"install/#installing-python-dependencies","title":"Installing Python dependencies","text":"<ol> <li>Activate your conda environment     <pre><code>conda activate your-env-name\n</code></pre></li> <li>If you are going to be following the tutorial in the usage guide, install this package + ipython:     <pre><code>pip install deepxromm[cli]\n</code></pre></li> <li>If you are a developer looking to install and use/extend this package in other Python scripts:     <pre><code>pip install deepxromm\n</code></pre></li> </ol>"},{"location":"usage/","title":"Usage Guide","text":"<p>There are two ways to use this package. You can either:</p> <ol> <li>Follow the usage guide below to run everything locally.</li> <li>Use the colab_tutorial.ipynb Jupyter Notebook and an online computing platform like Google Colab<ol> <li>If you are using this option, be sure to make a copy of the notebook before using it so that you can save your changes!</li> </ol> </li> </ol>"},{"location":"usage/#getting-started-and-creating-a-new-project","title":"Getting started and creating a new project","text":"<ol> <li>If you haven't already, follow the steps in the installation guide to install this package!</li> <li>Activate your conda environment     <pre><code>conda activate your-env-name\n</code></pre></li> <li>Open an interactive Python session     <pre><code>ipython\n</code></pre></li> <li>From the terminal, run the following commands (replacing <code>/path/to/project-folder</code> with the path to the folder for your project and <code>SD</code> with your initials):     <pre><code>from deepxromm import DeepXROMM \nworking_dir = '/path/to/project-folder'\nexperimenter = 'SD'\ndeepxromm = DeepXROMM.create_new_project(working_dir, experimenter)\n</code></pre><ol> <li>Optionally, you can change the way your input data is fed into DeepLabCut to create one network per camera view (<code>per_cam</code>) or blend the grayscale videos into an RGB video (<code>rgb</code>) by specifying the \"mode\" parameter. For example, for per_cam: <pre><code>deepxromm = DeepXROMM.create_new_project(working_dir, experimenter, mode='per_cam')\n</code></pre></li> <li>Keep your Python session open. We'll be running more commands here shortly</li> </ol> </li> <li>You should now see something that looks like this inside of your project folder:     <pre><code>sample-proj\n\u2502   project_config.yaml\n\u2502\n\u251c\u2500\u2500\u2500sample-proj-SD-YYYY-MM-DD\n\u251c\u2500\u2500\u2500trainingdata\n\u251c\u2500\u2500\u2500trials\n</code></pre></li> </ol>"},{"location":"usage/#exporting-your-data-from-xmalab-in-a-usable-format","title":"Exporting your data from XMAlab in a usable format","text":"<ol> <li>For now, DeepXROMM only supports analyzing full distorted videos (.avi). However, we understand that many labs use distorted .tif or .jpg stacks and plan to add support for these in a later release</li> <li>Along with your distorted videos, DeepXROMM expects CSV training data (XMAlab 2D points) exported with the following settings </li> </ol>"},{"location":"usage/#importing-your-data-and-loading-the-project","title":"Importing your data and loading the project","text":"<ol> <li>The simplest approach is to create a new folder inside of the trainingdata folder named after your trial and place your raw videos, as well as distorted 2D points from tracking, in the folder.</li> <li>There are also a number of options for customization in the project_config.yaml file. Check out the config file reference to learn more about what each variable does</li> <li>After you have added the trainingdata and/or trial folders, make sure to load the project. You should also reload it every time you update any settings.     <pre><code>deepxromm = DeepXROMM.load_project(working_dir)\n</code></pre></li> </ol>"},{"location":"usage/#training-the-project","title":"Training the project","text":"<ol> <li>To start training your network, run the following in your Python terminal     <pre><code>deepxromm.train_network()\n</code></pre></li> </ol>"},{"location":"usage/#using-a-trained-network-to-track-your-trials","title":"Using a trained network to track your trial(s)","text":"<ol> <li>Make sure any trials that you want to analyze are in appropriately named folders in the <code>trials</code> directory, and each folder contains a CSV and distorted cam1/cam2 videos that are named folder_name.csv, folder_name_cam1.avi, and folder_name_cam2.avi, respectively</li> <li>Run the following commands in your Python terminal:     <pre><code>from deepxromm import DeepXROMM\nworking_dir = '/path/to/project-folder'\ndeepxromm = DeepXROMM.load_project(working_dir)\ndeepxromm.analyze_videos()\n</code></pre></li> <li>This will save a file named trial_name-Predicted2DPoints.csv to the it# file (where number is the number next to iteration: in your project_folder/project-name-SD-YYYY-MM-DD/config.yaml file) inside of your trials/trial_name folder</li> <li>You can analyze the network's performance by importing this CSV as a 2D Points file into XMAlab with the following settings</li> </ol>"},{"location":"usage/#using-autocorrect","title":"Using autocorrect()","text":"<p>This package comes pre-built with autocorrect() functions that leverage the same image filtering functions as XMAlab, and use the marker's outline to do centroid detection on each marker. You can modify the autocorrect function's performance using the image processing parameters from the config file reference. You can also visualize the centroid detection process using the test_autocorrect() parameters.</p>"},{"location":"usage/#testing-autocorrect-parameters-on-a-single-markerframe-combination","title":"Testing autocorrect() parameters on a single marker/frame combination","text":"<p>You'll need a Python environment that is capable of displaying images, like a Jupyter Notebook, for these steps  </p> <ol> <li>Go to your project_config.yaml file and find the \"Autocorrect() Testing Vars\" section of the config  </li> <li>Change the value of test_autocorrect to true by replacing the word \"false\" with the word \"true\", like this: <pre><code>test_autocorrect: true\n</code></pre></li> <li>Specify a trial (trial_name), camera (cam), frame number (frame_num), and marker name (marker) to test the autocorrect function on  </li> <li>Import the package and initialize a deepxromm instance as a above and run the following code snippet     <pre><code>deepxromm.autocorrect_trial(working_dir)\n</code></pre></li> <li>Tune autocorrect() settings until you are satisfied with the testing output</li> </ol>"},{"location":"usage/#using-autocorrect-for-a-whole-trial","title":"Using autocorrect for a whole trial","text":"<ol> <li>If you tested autocorrect, set the test_autocorrect variable in your config file to false     <pre><code>test_autocorrect: false\n</code></pre></li> <li>Import the package and initialize a deepxromm instance as a above and run the following code snippet     <pre><code>deepxromm.autocorrect_trial()\n</code></pre></li> <li>This will save a file named trial_name-AutoCorrected2DPoints.csv to the it# file (where number is the number next to iteration: in your project_folder/project-name-SD-YYYY-MM-DD/config.yaml file) inside of your trials/trial_name folder     <pre><code>iteration: 0\n</code></pre></li> <li>You can analyze autocorrect's performance by importing this CSV as a 2D Points file into XMAlab with the following settings</li> </ol>"}]}